import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
import os
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import plotly.express as px
import plotly.graph_objects as go
from PIL import Image

# Sayfa yapÄ±landÄ±rmasÄ±
st.set_page_config(
    page_title="Meme Kanseri Tespiti",
    page_icon="ğŸ”¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

# BaÅŸlÄ±k ve aÃ§Ä±klama
st.title("Meme Kanseri Tespiti Projesi")
st.markdown("""
Bu uygulama, makine Ã¶ÄŸrenmesi modelleri kullanarak meme kanseri teÅŸhisine yardÄ±mcÄ± olmak iÃ§in geliÅŸtirilmiÅŸtir.
Wisconsin Meme Kanseri veri seti Ã¼zerinde eÄŸitilmiÅŸ modeller kullanÄ±larak yÃ¼ksek doÄŸrulukta tahminler yapabilmektedir.
""")

# Sidebar oluÅŸturma
st.sidebar.title("Navigasyon")
sayfalar = ["Ana Sayfa", "Veri Analizi", "Model KarÅŸÄ±laÅŸtÄ±rma", 
            "Model Yorumlama", "Tahmin", "Ensemble Modeller", "Ã–znitelik SeÃ§imi"]
sayfa = st.sidebar.selectbox("Sayfa SeÃ§in", sayfalar)

# Modelleri yÃ¼kleme
@st.cache_resource
def modelleri_yukle():
    modeller = {}
    model_klasoru = "modeller"
    
    if os.path.exists(model_klasoru):
        for model_dosyasi in os.listdir(model_klasoru):
            if model_dosyasi.endswith(".pkl"):
                model_adi = os.path.splitext(model_dosyasi)[0]
                model_yolu = os.path.join(model_klasoru, model_dosyasi)
                modeller[model_adi] = joblib.load(model_yolu)
    
    return modeller

# Veri setini yÃ¼kleme
@st.cache_data
def veri_setini_yukle():
    from sklearn.datasets import load_breast_cancer
    data = load_breast_cancer()
    df = pd.DataFrame(data.data, columns=data.feature_names)
    df['diagnosis'] = data.target
    return df, data

# GÃ¶rÃ¼ntÃ¼leri yÃ¼kleme
@st.cache_data
def goruntuleri_yukle():
    goruntu_klasoru = "goruntuler"
    goruntu_tipleri = {
        "veri_analizi": [],
        "model_karsilastirma": [],
        "model_yorumlama": [],
        "ensemble": [],
        "oznitelik_secimi": []
    }
    
    if os.path.exists(goruntu_klasoru):
        # KlasÃ¶rdeki gÃ¶rÃ¼ntÃ¼leri tara ve kategorize et
        for klasor, _, dosyalar in os.walk(goruntu_klasoru):
            for dosya in dosyalar:
                if dosya.endswith(('.png', '.jpg', '.jpeg')):
                    dosya_yolu = os.path.join(klasor, dosya)
                    
                    # GÃ¶rÃ¼ntÃ¼ tipine gÃ¶re sÄ±nÄ±flandÄ±r
                    if "veri_analizi" in dosya_yolu or "korelasyon" in dosya_yolu:
                        goruntu_tipleri["veri_analizi"].append(dosya_yolu)
                    elif "model_karsilastirma" in dosya_yolu or "roc_" in dosya_yolu.lower() or "confusion_matrix" in dosya_yolu:
                        goruntu_tipleri["model_karsilastirma"].append(dosya_yolu)
                    elif "model_yorumlama" in dosya_yolu or "oznitelik_onem" in dosya_yolu:
                        goruntu_tipleri["model_yorumlama"].append(dosya_yolu)
                    elif "ensemble" in dosya_yolu:
                        goruntu_tipleri["ensemble"].append(dosya_yolu)
                    elif "oznitelik_secimi" in dosya_yolu:
                        goruntu_tipleri["oznitelik_secimi"].append(dosya_yolu)
    
    return goruntu_tipleri

# Veri ve modelleri yÃ¼kleme
df, data = veri_setini_yukle()
modeller = modelleri_yukle()
goruntu_tipleri = goruntuleri_yukle()

# Ana Sayfa
if sayfa == "Ana Sayfa":
    st.header("Proje HakkÄ±nda")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.markdown("""
        ### Proje AmacÄ±
        Bu projede, makine Ã¶ÄŸrenmesi teknikleri kullanarak meme kanseri teÅŸhisi iÃ§in bir model geliÅŸtirilmiÅŸtir. 
        Proje, kanser teÅŸhisinde destek amaÃ§lÄ± bir araÃ§ olarak kullanÄ±labilir.
        
        ### KullanÄ±lan Veri Seti
        Wisconsin Meme Kanseri Veri Seti kullanÄ±lmÄ±ÅŸtÄ±r. Bu veri seti, meme kanseri hÃ¼crelerine ait 30 farklÄ± Ã¶znitelik iÃ§ermektedir.
        
        ### KullanÄ±lan Modeller
        - Lojistik Regresyon
        - Destek VektÃ¶r Makineleri (SVM)
        - Karar AÄŸaÃ§larÄ±
        - Rastgele Orman
        - Gradient Boosting
        - K-En YakÄ±n KomÅŸu (KNN)
        - Yapay Sinir AÄŸlarÄ±
        """)
    
    with col2:
        st.markdown("""
        ### NasÄ±l KullanÄ±lÄ±r?
        1. **Veri Analizi** sayfasÄ±nda veri seti hakkÄ±nda detaylÄ± bilgi edinebilirsiniz.
        2. **Model KarÅŸÄ±laÅŸtÄ±rma** sayfasÄ±nda farklÄ± modellerin performanslarÄ±nÄ± inceleyebilirsiniz.
        3. **Tahmin** sayfasÄ±nda kendi girdiÄŸiniz deÄŸerlerle tahmin yapabilirsiniz.
        
        ### En Ä°yi Performans
        Hiperparametre optimizasyonu sonucunda:
        - **Lojistik Regresyon**: Test doÄŸruluÄŸu: 0.9912, En iyi CV skoru: 0.978
        - **SVM**: Test doÄŸruluÄŸu: 0.9825, En iyi CV skoru: 0.9758
        - **Rastgele Orman**: Test doÄŸruluÄŸu: 0.9737, En iyi CV skoru: 0.9648
        """)
    
    st.markdown("---")
    st.subheader("Veri Seti DetaylarÄ±")
    
    # Veri seti gÃ¶rÃ¼ntÃ¼leme seÃ§enekleri
    if st.checkbox("Veri setini gÃ¶ster"):
        # TÃ¼m veri setini gÃ¶stermek iÃ§in seÃ§enekler
        gosterim_secenekleri = st.radio(
            "GÃ¶rÃ¼ntÃ¼leme SeÃ§enekleri:", 
            ["Ä°lk 5 satÄ±r", "TÃ¼m Veri Seti", "Ã–zet Ä°statistikler"],
            horizontal=True
        )
        
        if gosterim_secenekleri == "Ä°lk 5 satÄ±r":
            st.write(df.head())
        elif gosterim_secenekleri == "TÃ¼m Veri Seti":
            # Veri setinin boyutunu gÃ¶ster
            st.write(f"SatÄ±r sayÄ±sÄ±: {df.shape[0]}, SÃ¼tun sayÄ±sÄ±: {df.shape[1]}")
            
            # TÃ¼m veri setini gÃ¶stermek iÃ§in
            st.dataframe(df, height=600, use_container_width=True)
            
            # Sayfalama iÃ§in alternatif
            sayfa_boyutu = st.slider("Sayfa baÅŸÄ±na satÄ±r sayÄ±sÄ±", 10, 100, 50)
            sayfa_numarasi = st.number_input("Sayfa numarasÄ±", 1, int(np.ceil(df.shape[0]/sayfa_boyutu)), 1)
            
            baslangic = (sayfa_numarasi - 1) * sayfa_boyutu
            bitis = min(baslangic + sayfa_boyutu, df.shape[0])
            
            st.write(f"GÃ¶sterilen satÄ±rlar: {baslangic+1} - {bitis} / {df.shape[0]}")
            st.dataframe(df.iloc[baslangic:bitis], use_container_width=True)
            
        elif gosterim_secenekleri == "Ã–zet Ä°statistikler":
            st.write("Ã–znitelik istatistikleri:")
            st.write(df.describe())

# Veri Analizi SayfasÄ±
elif sayfa == "Veri Analizi":
    st.header("Veri Analizi ve GÃ¶rselleÅŸtirme")
    
    tab1, tab2, tab3 = st.tabs(["Veri DaÄŸÄ±lÄ±mlarÄ±", "Korelasyon Analizi", "PCA Analizi"])
    
    with tab1:
        st.subheader("Ã–znitelik DaÄŸÄ±lÄ±mlarÄ±")
        goruntuleri = [img for img in goruntu_tipleri["veri_analizi"] if any(k in img.lower() for k in ["dagilim", "distribution", "histogram", "sinif", "boxplot", "violinplot"])]
        
        if goruntuleri:
            for goruntu in goruntuleri:
                st.image(goruntu, use_container_width=True, caption=os.path.basename(goruntu))
        else:
            st.warning("Veri daÄŸÄ±lÄ±m gÃ¶rÃ¼ntÃ¼leri bulunamadÄ±. LÃ¼tfen 'veri_analizi.py' scriptini Ã§alÄ±ÅŸtÄ±rarak gÃ¶rÃ¼ntÃ¼leri oluÅŸturun.")
    
    with tab2:
        st.subheader("Korelasyon Analizi")
        goruntuleri = [img for img in goruntu_tipleri["veri_analizi"] if any(k in img.lower() for k in ["korelasyon", "correlation", "heatmap"])]
        
        if goruntuleri:
            for goruntu in goruntuleri:
                st.image(goruntu, use_container_width=True, caption=os.path.basename(goruntu))
        
        # Ä°nteraktif korelasyon matrisi
        st.subheader("Ä°nteraktif Korelasyon Matrisi")
        correlation = df.corr()
        fig = px.imshow(correlation, text_auto=True, aspect="auto")
        st.plotly_chart(fig, use_container_width=True)
    
    with tab3:
        st.subheader("PCA Analizi")
        goruntuleri = [img for img in goruntu_tipleri["veri_analizi"] if "pca" in img.lower()]
        
        if goruntuleri:
            for goruntu in goruntuleri:
                st.image(goruntu, use_container_width=True, caption=os.path.basename(goruntu))
            
        # Ä°nteraktif PCA
        st.subheader("Ä°nteraktif PCA GrafiÄŸi")
        
        X = df.drop('diagnosis', axis=1)
        y = df['diagnosis']
        
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        
        pca = PCA(n_components=3)
        X_pca = pca.fit_transform(X_scaled)
        
        pca_df = pd.DataFrame(
            data=X_pca, 
            columns=['PC1', 'PC2', 'PC3']
        )
        pca_df['diagnosis'] = y.map({0: 'Malign (KÃ¶tÃ¼ Huylu)', 1: 'Benign (Ä°yi Huylu)'})
        
        fig = px.scatter_3d(
            pca_df, x='PC1', y='PC2', z='PC3', color='diagnosis',
            opacity=0.7, color_discrete_map={'Malign (KÃ¶tÃ¼ Huylu)': 'red', 'Benign (Ä°yi Huylu)': 'blue'}
        )
        st.plotly_chart(fig, use_container_width=True)
        
        st.write(f"AÃ§Ä±klanan Varyans OranÄ±: {pca.explained_variance_ratio_}")
        
        # AÃ§Ä±klanan varyans oranÄ± grafiÄŸi
        explained_var = np.append(pca.explained_variance_ratio_, 
                                 np.sum(pca.explained_variance_ratio_[3:]))
        labels = ['PC1', 'PC2', 'PC3', 'DiÄŸer PC\'ler']
        
        fig = px.pie(values=explained_var, names=labels, title='PCA BileÅŸenlerinin AÃ§Ä±kladÄ±ÄŸÄ± Varyans')
        st.plotly_chart(fig, use_container_width=True)

# Model KarÅŸÄ±laÅŸtÄ±rma SayfasÄ±
elif sayfa == "Model KarÅŸÄ±laÅŸtÄ±rma":
    st.header("Model KarÅŸÄ±laÅŸtÄ±rma")
    
    tab1, tab2, tab3, tab4 = st.tabs(["DoÄŸruluk KarÅŸÄ±laÅŸtÄ±rmasÄ±", "ROC EÄŸrileri", "Confusion Matrix", "Precision-Recall EÄŸrileri"])
    
    with tab1:
        st.subheader("Model DoÄŸruluk KarÅŸÄ±laÅŸtÄ±rmasÄ±")
        goruntuleri = [img for img in goruntu_tipleri["model_karsilastirma"] if any(k in img.lower() for k in ["accuracy", "comparison", "dogruluk", "karsilastirma"])]
        
        if goruntuleri:
            for goruntu in goruntuleri:
                st.image(goruntu, use_container_width=True, caption=os.path.basename(goruntu))
        else:
            st.warning("DoÄŸruluk karÅŸÄ±laÅŸtÄ±rma gÃ¶rselleri bulunamadÄ±.")
            
        # Model karÅŸÄ±laÅŸtÄ±rma tablosu
        model_sonuclari = {
            "Lojistik Regresyon": {"Test DoÄŸruluÄŸu": 0.9912, "CV Skoru": 0.9780},
            "SVM": {"Test DoÄŸruluÄŸu": 0.9825, "CV Skoru": 0.9758},
            "Rastgele Orman": {"Test DoÄŸruluÄŸu": 0.9737, "CV Skoru": 0.9648},
            "Gradient Boosting": {"Test DoÄŸruluÄŸu": 0.9561, "CV Skoru": 0.9626},
            "Yapay Sinir AÄŸÄ±": {"Test DoÄŸruluÄŸu": 0.9737, "CV Skoru": 0.9780}
        }
        
        sonuc_df = pd.DataFrame.from_dict(model_sonuclari, orient='index')
        st.table(sonuc_df)
        
        # Ä°nteraktif model karÅŸÄ±laÅŸtÄ±rma grafiÄŸi
        fig = go.Figure()
        
        fig.add_trace(go.Bar(
            x=list(model_sonuclari.keys()),
            y=[model["Test DoÄŸruluÄŸu"] for model in model_sonuclari.values()],
            name='Test DoÄŸruluÄŸu',
            marker_color='indianred'
        ))
        
        fig.add_trace(go.Bar(
            x=list(model_sonuclari.keys()),
            y=[model["CV Skoru"] for model in model_sonuclari.values()],
            name='CV Skoru',
            marker_color='lightsalmon'
        ))
        
        fig.update_layout(
            title='Model Performans KarÅŸÄ±laÅŸtÄ±rmasÄ±',
            xaxis_tickfont_size=14,
            yaxis=dict(
                title=dict(
                    text='Skor',
                    font=dict(size=16)
                ),
                tickfont=dict(size=14),
                range=[0.90, 1.0]
            ),
            legend=dict(
                x=0,
                y=1.0,
                bgcolor='rgba(255, 255, 255, 0)',
                bordercolor='rgba(255, 255, 255, 0)'
            ),
            barmode='group',
            bargap=0.15,
            bargroupgap=0.1
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    with tab2:
        st.subheader("ROC EÄŸrileri")
        goruntuleri = [img for img in goruntu_tipleri["model_karsilastirma"] if "roc" in img.lower()]
        
        if goruntuleri:
            st.subheader("TÃ¼m Modeller ROC EÄŸrisi")
            tum_modeller_roc = [img for img in goruntuleri if "tum" in img.lower() or "all" in img.lower()]
            if tum_modeller_roc:
                st.image(tum_modeller_roc[0], use_container_width=True, caption=os.path.basename(tum_modeller_roc[0]))
            
            st.subheader("Modellere GÃ¶re ROC EÄŸrileri")
            bireysel_roc = [img for img in goruntuleri if not ("tum" in img.lower() or "all" in img.lower())]
            
            # ROC eÄŸrilerini iki sÃ¼tunda gÃ¶ster
            cols = st.columns(2)
            for i, goruntu in enumerate(bireysel_roc):
                with cols[i % 2]:
                    st.image(goruntu, use_container_width=True, caption=os.path.basename(goruntu))
        else:
            st.warning("ROC eÄŸrisi gÃ¶rselleri bulunamadÄ±.")
    
    with tab3:
        st.subheader("Confusion Matrix")
        goruntuleri = [img for img in goruntu_tipleri["model_karsilastirma"] if "cm" in img.lower() or "confusion" in img.lower()]
        
        if goruntuleri:
            # Confusion Matrix'leri iki sÃ¼tunda gÃ¶ster
            cols = st.columns(2)
            for i, goruntu in enumerate(goruntuleri):
                with cols[i % 2]:
                    st.image(goruntu, use_container_width=True, caption=os.path.basename(goruntu))
        else:
            st.warning("Confusion Matrix gÃ¶rselleri bulunamadÄ±.")
            
    with tab4:
        st.subheader("Precision-Recall EÄŸrileri")
        pr_goruntuleri = [img for img in goruntu_tipleri["model_karsilastirma"] if "precision" in img.lower() or "recall" in img.lower()]
        
        if pr_goruntuleri:
            st.subheader("TÃ¼m Modeller Precision-Recall EÄŸrisi")
            tum_modeller_pr = [img for img in pr_goruntuleri if "tum_modeller" in img.lower()]
            if tum_modeller_pr:
                st.image(tum_modeller_pr[0], use_container_width=True, caption=os.path.basename(tum_modeller_pr[0]))
            
            karsilastirma_pr = [img for img in pr_goruntuleri if "karsilastirma" in img.lower()]
            if karsilastirma_pr:
                st.image(karsilastirma_pr[0], use_container_width=True, caption="Precision, Recall ve F1 KarÅŸÄ±laÅŸtÄ±rmasÄ±")
            
            st.subheader("Modellere GÃ¶re Precision-Recall EÄŸrileri")
            bireysel_pr = [img for img in pr_goruntuleri if not ("tum_modeller" in img.lower() or "karsilastirma" in img.lower())]
            
            # Precision-Recall eÄŸrilerini iki sÃ¼tunda gÃ¶ster
            cols = st.columns(2)
            for i, goruntu in enumerate(bireysel_pr):
                with cols[i % 2]:
                    st.image(goruntu, use_container_width=True, caption=os.path.basename(goruntu))
        else:
            st.warning("Precision-Recall eÄŸrisi gÃ¶rselleri bulunamadÄ±.")
            
    st.subheader("Ã–nemli Ã–znitelikler")
    onem_goruntuleri = [img for img in goruntu_tipleri["veri_analizi"] if any(k in img.lower() for k in ["feature_importance", "importance", "Ã¶znitelik", "onem"])]
    
    if onem_goruntuleri:
        for goruntu in onem_goruntuleri:
            st.image(goruntu, use_container_width=True, caption=os.path.basename(goruntu))
    else:
        st.warning("Ã–znitelik Ã¶nem analizi gÃ¶rselleri bulunamadÄ±.")

# Model Yorumlama SayfasÄ±
elif sayfa == "Model Yorumlama":
    st.header("Model Yorumlama")
    
    st.subheader("Ã–znitelik Ã–nem Analizi")
    
    # GÃ¶rsel ve sekmeler
    tab1, tab2 = st.tabs(["Dahili Ã–nem", "PermÃ¼tasyon Ã–nem"])
    
    with tab1:
        st.info("Dahili Ã¶nem, modelin eÄŸitim sÃ¼recinde Ã¶zniteliklere atanan aÄŸÄ±rlÄ±klarÄ± gÃ¶sterir. Bu deÄŸerler, modelin her Ã¶zniteliÄŸe verdiÄŸi Ã¶nemi yansÄ±tÄ±r.")
        
        # Dahili Ã¶nem gÃ¶rselleri
        dahili_onem_goruntuleri = [img for img in goruntu_tipleri["model_yorumlama"] if "feature_importance" in img.lower() and not "permutation" in img.lower()]
        
        if dahili_onem_goruntuleri:
            # Ä°lk olarak karÅŸÄ±laÅŸtÄ±rma gÃ¶rselini gÃ¶ster
            karsilastirma_goruntu = [img for img in dahili_onem_goruntuleri if "karsilastirma_onem" in img.lower()]
            if karsilastirma_goruntu:
                st.image(karsilastirma_goruntu[0], use_container_width=True, caption="Modeller ArasÄ± Ã–znitelik Ã–nem KarÅŸÄ±laÅŸtÄ±rmasÄ±")
            
            # Sonra her modelin kendi gÃ¶rselini gÃ¶ster
            bireysel_goruntuleri = [img for img in dahili_onem_goruntuleri if not "karsilastirma" in img.lower()]
            
            for goruntu in bireysel_goruntuleri:
                st.image(goruntu, use_container_width=True, caption=os.path.basename(goruntu))
        else:
            st.warning("Dahili Ã¶nem gÃ¶rselleri bulunamadÄ±.")
    
    with tab2:
        st.info("PermÃ¼tasyon Ã¶nem analizi, bir Ã¶zniteliÄŸin deÄŸerlerini karÄ±ÅŸtÄ±rarak modelin performans deÄŸiÅŸimini Ã¶lÃ§er. EÄŸer bir Ã¶zniteliÄŸin deÄŸerleri karÄ±ÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda performans Ã§ok dÃ¼ÅŸerse, o Ã¶znitelik Ã¶nemlidir.")
        
        # PermÃ¼tasyon Ã¶nem gÃ¶rselleri
        permutasyon_onem_goruntuleri = [img for img in goruntu_tipleri["model_yorumlama"] if "permutation" in img.lower()]
        
        if permutasyon_onem_goruntuleri:
            # Ä°lk olarak karÅŸÄ±laÅŸtÄ±rma gÃ¶rselini gÃ¶ster
            perm_karsilastirma = [img for img in permutasyon_onem_goruntuleri if "karsilastirma" in img.lower()]
            if perm_karsilastirma:
                st.image(perm_karsilastirma[0], use_container_width=True, caption="Modeller ArasÄ± PermÃ¼tasyon Ã–nem KarÅŸÄ±laÅŸtÄ±rmasÄ±")
            
            # Sonra her modelin kendi gÃ¶rselini gÃ¶ster
            perm_bireysel = [img for img in permutasyon_onem_goruntuleri if not "karsilastirma" in img.lower()]
            
            for goruntu in perm_bireysel:
                st.image(goruntu, use_container_width=True, caption=os.path.basename(goruntu))
        else:
            st.warning("PermÃ¼tasyon Ã¶nem gÃ¶rselleri bulunamadÄ±.")
            
    st.subheader("Ã–znitelik Analizi Yorumu")
    st.markdown("""
    ### Ã–znitelik Ã–nemlerinin Analizi:
    
    **En Ã–nemli Ã–znitelikler:**
    
    1. **mean concave points (Ortalama konkav noktalar)**: HÃ¼cre Ã§ekirdeÄŸinin konturu Ã¼zerindeki iÃ§bÃ¼key bÃ¶lgelerin ortalama sayÄ±sÄ±. Bu Ã¶znitelik, kÃ¶tÃ¼ huylu tÃ¼mÃ¶rlerin teÅŸhisinde en ayÄ±rt edici faktÃ¶rlerden biridir.
    
    2. **worst concave points (En kÃ¶tÃ¼ konkav noktalar)**: En kÃ¶tÃ¼ hÃ¼cre Ã§ekirdeÄŸindeki iÃ§bÃ¼key bÃ¶lgelerin sayÄ±sÄ±. Bu da kÃ¶tÃ¼ huylu tÃ¼mÃ¶rlerin belirlenmesinde kritik Ã¶neme sahip.
    
    3. **worst radius (En kÃ¶tÃ¼ yarÄ±Ã§ap)**: En kÃ¶tÃ¼ hÃ¼cre Ã§ekirdeÄŸinin yarÄ±Ã§apÄ±, tÃ¼mÃ¶r hÃ¼crelerinin boyutundaki anormallikleri iÅŸaret eder.
    
    4. **worst perimeter (En kÃ¶tÃ¼ Ã§evre)**: En kÃ¶tÃ¼ hÃ¼cre Ã§ekirdeÄŸinin Ã§evresi, tÃ¼mÃ¶r hÃ¼crelerinin ÅŸekil bozukluklarÄ±nÄ± gÃ¶sterir.
    
    5. **mean texture (Ortalama doku)**: HÃ¼cre Ã§ekirdeÄŸinin gri seviye deÄŸerlerindeki standart sapma, doku dÃ¼zensizliÄŸini gÃ¶sterir.
    
    **Klinik Ã–nemi:**
    
    Bu analiz, meme kanseri tespitinde en kritik faktÃ¶rlerin hÃ¼cre Ã§ekirdeÄŸinin ÅŸekil Ã¶zellikleri olduÄŸunu gÃ¶stermektedir. Ã–zellikle iÃ§bÃ¼key noktalar (concave points), hÃ¼cre zarÄ±nÄ±n iÃ§e doÄŸru girinti yapan bÃ¶lÃ¼mleri, kÃ¶tÃ¼ huylu tÃ¼mÃ¶rlerin karakteristik bir Ã¶zelliÄŸidir.
    
    Modeller arasÄ±ndaki tutarlÄ±lÄ±k, bu Ã¶zniteliklerin gerÃ§ekten Ã¶nemli olduÄŸunu doÄŸrulamaktadÄ±r. Doktorlar, bu faktÃ¶rlere Ã¶zellikle dikkat ederek teÅŸhis sÃ¼recini geliÅŸtirebilirler.
    """)

# Tahmin SayfasÄ±
elif sayfa == "Tahmin":
    st.header("Kanser Tahmini")
    
    st.markdown("""
    AÅŸaÄŸÄ±daki formu doldurarak yeni bir Ã¶rnek iÃ§in kanser tahmini yapabilirsiniz.
    **Not:** GerÃ§ek tÄ±bbi teÅŸhis yerine geÃ§mez, sadece bilgi amaÃ§lÄ±dÄ±r.
    """)
    
    # Kategorilere gÃ¶re Ã¶znitelikleri gruplayalÄ±m
    ozellik_gruplari = {
        "Radius (YarÄ±Ã§ap)": ["mean radius", "radius error", "worst radius"],
        "Texture (Doku)": ["mean texture", "texture error", "worst texture"],
        "Perimeter (Ã‡evre)": ["mean perimeter", "perimeter error", "worst perimeter"],
        "Area (Alan)": ["mean area", "area error", "worst area"],
        "Smoothness (PÃ¼rÃ¼zsÃ¼zlÃ¼k)": ["mean smoothness", "smoothness error", "worst smoothness"],
        "Compactness (YoÄŸunluk)": ["mean compactness", "compactness error", "worst compactness"],
        "Concavity (Ä°Ã§bÃ¼keylik)": ["mean concavity", "concavity error", "worst concavity"],
        "Concave Points (Ä°Ã§bÃ¼key Noktalar)": ["mean concave points", "concave points error", "worst concave points"],
        "Symmetry (Simetri)": ["mean symmetry", "symmetry error", "worst symmetry"],
        "Fractal Dimension (Fraktal Boyut)": ["mean fractal dimension", "fractal dimension error", "worst fractal dimension"]
    }
    
    # VarsayÄ±lan deÄŸerler (ortalama deÄŸerler)
    default_values = df.drop('diagnosis', axis=1).mean().to_dict()
    
    # Tahmin iÃ§in kullanÄ±lacak deÄŸerler
    girilen_degerler = {}
    
    # Modeli seÃ§me
    model_secimi = st.selectbox(
        "Tahmin iÃ§in model seÃ§in:",
        ["Lojistik Regresyon", "SVM", "Rastgele Orman", "Gradient Boosting", "Yapay Sinir AÄŸÄ±"]
    )
    
    # GruplarÄ± sekmelerde gÃ¶sterelim
    grup_sekmeler = st.tabs(list(ozellik_gruplari.keys()))
    
    for i, (grup_adi, ozellikler) in enumerate(ozellik_gruplari.items()):
        with grup_sekmeler[i]:
            st.subheader(f"{grup_adi} Ã–zellikleri")
            
            for ozellik in ozellikler:
                girilen_degerler[ozellik] = st.slider(
                    f"{ozellik}",
                    float(df[ozellik].min()),
                    float(df[ozellik].max()),
                    float(default_values[ozellik]),
                    step=0.1,
                    format="%.2f"
                )
    
    # Tahmin butonu
    if st.button("Tahmin Yap"):
        # Girilen deÄŸerleri vektÃ¶r haline getirme
        girdi_vektor = pd.DataFrame([girilen_degerler])
        
        # DoÄŸru model ismini map etme
        model_map = {
            "Lojistik Regresyon": "logistic_regression_optimized",
            "SVM": "svm_optimized",
            "Rastgele Orman": "random_forest_optimized",
            "Gradient Boosting": "gradient_boosting_optimized",
            "Yapay Sinir AÄŸÄ±": "neural_network_optimized"
        }
        
        # VarsayÄ±lan model (eÄŸer seÃ§ilen model bulunamazsa)
        varsayilan_model = next(iter(modeller.values()))
        
        # SeÃ§ilen modeli al
        secilen_model_ismi = model_map.get(model_secimi)
        model = modeller.get(secilen_model_ismi, varsayilan_model)
        
        # Tahmin yap
        tahmin = model.predict(girdi_vektor)
        tahmin_olasiligi = model.predict_proba(girdi_vektor)
        
        # SonuÃ§larÄ± gÃ¶ster
        sonuc_container = st.container()
        with sonuc_container:
            if tahmin[0] == 1:
                st.success("**Tahmin: Benign (Ä°yi Huylu)**")
                st.markdown(f"OlasÄ±lÄ±k: **{tahmin_olasiligi[0][1]:.2%}**")
                st.markdown("Bu tahmin, incelenen hÃ¼cre Ã¶rneÄŸinin iyi huylu (benign) olduÄŸunu gÃ¶stermektedir.")
            else:
                st.error("**Tahmin: Malign (KÃ¶tÃ¼ Huylu)**")
                st.markdown(f"OlasÄ±lÄ±k: **{tahmin_olasiligi[0][0]:.2%}**")
                st.markdown("Bu tahmin, incelenen hÃ¼cre Ã¶rneÄŸinin kÃ¶tÃ¼ huylu (malign) olduÄŸunu gÃ¶stermektedir.")
            
            st.warning("**Not:** Bu sonuÃ§ sadece bilgi amaÃ§lÄ±dÄ±r ve gerÃ§ek tÄ±bbi teÅŸhis yerine geÃ§mez. LÃ¼tfen gerÃ§ek teÅŸhis iÃ§in bir doktora baÅŸvurun.")
            
            # Ä°nteraktif donut chart
            labels = ["Malign (KÃ¶tÃ¼ Huylu)", "Benign (Ä°yi Huylu)"]
            values = [tahmin_olasiligi[0][0], tahmin_olasiligi[0][1]]
            
            fig = go.Figure(data=[go.Pie(
                labels=labels,
                values=values,
                hole=.4,
                marker_colors=['#FF6B6B', '#4CAF50']
            )])
            
            fig.update_layout(
                title_text="Tahmin OlasÄ±lÄ±ÄŸÄ±",
                annotations=[dict(text=f"{max(values):.1%}", x=0.5, y=0.5, font_size=20, showarrow=False)]
            )
            
            st.plotly_chart(fig, use_container_width=True)

# Ensemble Modeller SayfasÄ±
elif sayfa == "Ensemble Modeller":
    st.title("Ensemble Ã–ÄŸrenme Teknikleri")
    
    st.markdown("""
    ## Ensemble (Topluluk) Modelleri Nedir?
    
    Ensemble (topluluk) Ã¶ÄŸrenme, birden fazla modelin bir arada kullanÄ±larak daha iyi performans elde edilmesini saÄŸlayan bir tekniktir. 
    Bu projede aÅŸaÄŸÄ±daki ensemble teknikleri uygulanmÄ±ÅŸtÄ±r:
    
    1. **Hard Voting:** Her model bir sÄ±nÄ±f tahmini yapar ve en Ã§ok oy alan sÄ±nÄ±f seÃ§ilir.
    2. **Soft Voting:** Her model olasÄ±lÄ±k deÄŸerleri Ã¼retir ve bu olasÄ±lÄ±klarÄ±n ortalamasÄ± alÄ±narak final tahmin yapÄ±lÄ±r.
    3. **Stacking:** Birinci seviye modellerin tahminleri, ikinci seviye bir meta-model tarafÄ±ndan birleÅŸtirilir.
    4. **Advanced Stacking:** Stacking'in daha geliÅŸmiÅŸ bir versiyonu, Ã§apraz doÄŸrulama ile tahminlerin kalitesini artÄ±rÄ±r.
    """)
    
    # GÃ¶rsel seÃ§imi
    ensemble_gorselleri = goruntu_tipleri["ensemble"]
    
    if len(ensemble_gorselleri) == 0:
        st.warning("Ensemble model gÃ¶rselleri bulunamadÄ±. LÃ¼tfen Ã¶nce 'ensemble_ogrenme.py' scriptini Ã§alÄ±ÅŸtÄ±rÄ±n.")
    else:
        # GÃ¶rsel kategorileri
        gorsel_kategorileri = {
            "DoÄŸruluk KarÅŸÄ±laÅŸtÄ±rmasÄ±": "accuracy_karsilastirma.png",
            "ROC EÄŸrileri": "roc_karsilastirma.png",
            "Precision-Recall EÄŸrileri": "precision_recall_karsilastirma.png",
            "TÃ¼m Metrikler": "tum_metrikler_karsilastirma.png",
            "Confusion Matrisleri": "confusion_matrices.png"
        }
        
        # Sekmeler oluÅŸtur
        tabs = st.tabs(list(gorsel_kategorileri.keys()))
        
        for i, (tab_isim, gorsel_isim) in enumerate(gorsel_kategorileri.items()):
            with tabs[i]:
                # Ä°lgili gÃ¶rseli bul
                for gorsel in ensemble_gorselleri:
                    if gorsel_isim in gorsel:
                        st.image(gorsel, caption=tab_isim, use_column_width=True)
                        break
        
        # SonuÃ§larÄ±n aÃ§Ä±klamasÄ±
        st.markdown("""
        ## Analiz SonuÃ§larÄ±
        
        Ensemble modellerin karÅŸÄ±laÅŸtÄ±rmalÄ± analizi sonucunda:
        
        1. **DoÄŸruluk (Accuracy):** Lojistik Regresyon bireysel model olarak en yÃ¼ksek doÄŸruluk deÄŸerine sahiptir (%99.12). Hard Voting ensemble modeli (%98.25) de iyi bir performans gÃ¶stermiÅŸtir.
        
        2. **AUC DeÄŸeri:** Bireysel modeller iÃ§inde Lojistik Regresyon en yÃ¼ksek AUC deÄŸerine sahipken (0.9987), ensemble modellerinden Soft Voting, Stacking ve Advanced Stacking yÃ¼ksek AUC performansÄ± (0.9971) gÃ¶stermiÅŸtir.
        
        3. **F1 Skoru:** Lojistik Regresyon en yÃ¼ksek F1 skoruna sahiptir (0.9930). Ensemble modellerinden Hard Voting ikinci sÄ±rada yer almaktadÄ±r (0.9861).
        
        4. **KararlÄ±lÄ±k (Stability):** Cross-validation sonuÃ§larÄ±na gÃ¶re Hard Voting ensemble modeli en kararlÄ± performansa sahip modellerden biri olarak Ã¶ne Ã§Ä±kmaktadÄ±r (standart sapma: 0.0082).
        
        5. **Genel DeÄŸerlendirme:** Bu veri seti iÃ§in ensemble modeller, bireysel bazÄ± modelleri geÃ§emese de, genellikle daha kararlÄ± ve gÃ¼venilir sonuÃ§lar verme eÄŸilimindedir. Ã–zellikle daha karmaÅŸÄ±k ve bÃ¼yÃ¼k veri setlerinde, ensemble modellerin avantajlarÄ± daha belirgin olabilir.
        """)
        
        # Model sonuÃ§larÄ± tablosu
        st.subheader("Model Performans Metrikleri")
        
        metrikler_df = pd.DataFrame({
            "Model": ["Lojistik Regresyon", "SVM", "Rastgele Orman", "Gradient Boosting", "Yapay Sinir AÄŸÄ±", 
                     "Hard Voting", "Soft Voting", "Stacking", "Advanced Stacking"],
            "Accuracy": [0.9912, 0.9825, 0.9737, 0.9561, 0.9737, 0.9825, 0.9737, 0.9737, 0.9737],
            "AUC": [0.9987, 0.9974, 0.9974, 0.9938, 0.9954, 0.9767, 0.9971, 0.9971, 0.9971],
            "F1 Score": [0.9930, 0.9861, 0.9790, 0.9650, 0.9790, 0.9861, 0.9790, 0.9790, 0.9790],
            "Precision": [0.9861, 0.9726, 0.9722, 0.9583, 0.9722, 0.9726, 0.9722, 0.9722, 0.9722],
            "Recall": [1.0000, 1.0000, 0.9859, 0.9718, 0.9859, 1.0000, 0.9859, 0.9859, 0.9859],
        })
        
        st.dataframe(metrikler_df, use_container_width=True)
        
        st.markdown("""
        ## SonuÃ§ ve Ã–neriler
        
        Ensemble modeller, bu Ã¶zel veri seti iÃ§in bireysel bazÄ± modelleri geÃ§emese de, genellikle daha kararlÄ± ve gÃ¼venilir sonuÃ§lar verme eÄŸilimindedir. Ã–zellikle daha karmaÅŸÄ±k ve bÃ¼yÃ¼k veri setlerinde, ensemble modellerin avantajlarÄ± daha belirgin olabilir.
        
        **Ã–neriler:**
        
        1. Daha bÃ¼yÃ¼k ve karmaÅŸÄ±k veri setleri Ã¼zerinde ensemble teknikleri daha bÃ¼yÃ¼k bir avantaj saÄŸlayabilir.
        2. FarklÄ± hiperparametre kombinasyonlarÄ± ile ensemble modellerin performansÄ± daha da artÄ±rÄ±labilir.
        3. AÄŸÄ±rlÄ±klÄ± oylama (weighted voting) gibi daha sofistike ensemble tekniklerinin denenmesi faydalÄ± olabilir.
        4. Ensemble modellerin eÄŸitim sÃ¼resi daha uzun olduÄŸundan, gerÃ§ek zamanlÄ± uygulamalar iÃ§in performans-doÄŸruluk dengesi gÃ¶zetilmelidir.
        """)

# Ã–znitelik SeÃ§imi SayfasÄ±
elif sayfa == "Ã–znitelik SeÃ§imi":
    st.title("Ã–znitelik SeÃ§imi Teknikleri")
    
    st.markdown("""
    ## Ã–znitelik SeÃ§imi Nedir?
    
    Ã–znitelik seÃ§imi, makine Ã¶ÄŸrenmesi modellerinin eÄŸitiminde kullanÄ±lan Ã¶zniteliklerin (deÄŸiÅŸkenlerin) 
    en Ã¶nemlilerini belirleyerek boyutsallÄ±ÄŸÄ± azaltan bir tekniktir. Bu teknik ÅŸu avantajlarÄ± saÄŸlar:
    
    1. **Daha hÄ±zlÄ± eÄŸitim**: Daha az sayÄ±da deÄŸiÅŸkenle eÄŸitim sÃ¼resi kÄ±salÄ±r.
    2. **Daha iyi genelleme**: GÃ¼rÃ¼ltÃ¼ iÃ§eren veya alakasÄ±z Ã¶znitelikler Ã§Ä±karÄ±lÄ±r.
    3. **Daha yorumlanabilir modeller**: Hangi Ã¶zelliklerin gerÃ§ekten Ã¶nemli olduÄŸunu gÃ¶rmek, sonuÃ§larÄ± anlamayÄ± kolaylaÅŸtÄ±rÄ±r.
    4. **Bellek kullanÄ±mÄ±nÄ± azaltma**: Ã–zellikle bÃ¼yÃ¼k veri setlerinde kaynaklarÄ± daha verimli kullanmayÄ± saÄŸlar.
    
    Bu projede aÅŸaÄŸÄ±daki Ã¶znitelik seÃ§im teknikleri uygulanmÄ±ÅŸtÄ±r:
    """)
    
    # Teknik aÃ§Ä±klamalarÄ±
    teknoloji_aciklamalari = {
        "ANOVA F-deÄŸeri": "Ä°statistiksel bir test olan ANOVA F-testi kullanarak, her bir Ã¶zniteliÄŸin hedef deÄŸiÅŸkenle olan iliÅŸkisini deÄŸerlendirir.",
        "Mutual Information": "Ã–znitelik ve hedef arasÄ±ndaki karÅŸÄ±lÄ±klÄ± bilgiyi Ã¶lÃ§er. DoÄŸrusal olmayan iliÅŸkileri de yakalayabilir.",
        "RFE (Lojistik Regresyon)": "Recursive Feature Elimination, Ã¶zyinelemeli Ã¶znitelik eleme tekniÄŸidir. TÃ¼m Ã¶zniteliklerle baÅŸlayÄ±p en Ã¶nemsizleri adÄ±m adÄ±m Ã§Ä±karÄ±r.",
        "Random Forest Ã–nem": "Random Forest modelinin Ã¶znitelik Ã¶nem skorlarÄ±nÄ± kullanarak en Ã¶nemli Ã¶znitelikleri seÃ§er.",
        "Gradient Boosting Ã–nem": "Gradient Boosting modelinin belirlediÄŸi Ã¶znitelik Ã¶nem skorlarÄ±na gÃ¶re seÃ§im yapar.",
        "PCA": "Temel BileÅŸen Analizi, veriyi daha dÃ¼ÅŸÃ¼k boyutlu bir uzaya dÃ¶nÃ¼ÅŸtÃ¼ren bir boyut indirgeme tekniÄŸidir."
    }
    
    # Ã–znitelik seÃ§im yÃ¶ntemleri
    col1, col2 = st.columns([1, 1])
    
    with col1:
        for teknik, aciklama in list(teknoloji_aciklamalari.items())[:3]:
            st.markdown(f"### {teknik}")
            st.markdown(aciklama)
            
    with col2:
        for teknik, aciklama in list(teknoloji_aciklamalari.items())[3:]:
            st.markdown(f"### {teknik}")
            st.markdown(aciklama)
    
    # GÃ¶rsel sonuÃ§larÄ±
    oznitelik_secimi_gorselleri = goruntu_tipleri["oznitelik_secimi"]
    
    if len(oznitelik_secimi_gorselleri) == 0:
        st.warning("Ã–znitelik seÃ§imi gÃ¶rselleri bulunamadÄ±. LÃ¼tfen Ã¶nce 'oznitelik_secimi.py' scriptini Ã§alÄ±ÅŸtÄ±rÄ±n.")
    else:
        # SeÃ§ilen Ã¶znitelikler karÅŸÄ±laÅŸtÄ±rmasÄ±
        st.header("SeÃ§ilen Ã–znitelikler KarÅŸÄ±laÅŸtÄ±rmasÄ±")
        karsilastirma_gorseli = [img for img in oznitelik_secimi_gorselleri if "secilen_oznitelikler_karsilastirma" in img]
        if karsilastirma_gorseli:
            st.image(karsilastirma_gorseli[0], use_container_width=True, 
                     caption="FarklÄ± YÃ¶ntemlerle SeÃ§ilen Ã–zniteliklerin KarÅŸÄ±laÅŸtÄ±rmasÄ±")
            
            st.markdown("""
            **GÃ¶zlem**: YukarÄ±daki Ä±sÄ± haritasÄ± (heatmap) farklÄ± Ã¶znitelik seÃ§im yÃ¶ntemlerinin hangi Ã¶zniteliÄŸi seÃ§tiÄŸini gÃ¶stermektedir.
            Mavi renkli hÃ¼creler ilgili yÃ¶ntemin o Ã¶zniteliÄŸi seÃ§tiÄŸini gÃ¶sterir. BirÃ§ok yÃ¶ntem tarafÄ±ndan ortak seÃ§ilen Ã¶znitelikler,
            genel olarak daha Ã¶nemli olma eÄŸilimindedir.
            """)
        
        # Performans karÅŸÄ±laÅŸtÄ±rmasÄ±
        st.header("Performans KarÅŸÄ±laÅŸtÄ±rmasÄ±")
        
        # TÃ¼m metrikler karÅŸÄ±laÅŸtÄ±rmasÄ±
        tum_metrikler_gorseli = [img for img in oznitelik_secimi_gorselleri if "tum_metrikler_karsilastirma" in img]
        if tum_metrikler_gorseli:
            st.image(tum_metrikler_gorseli[0], use_container_width=True,
                    caption="Ã–znitelik SeÃ§im YÃ¶ntemlerinin Performans KarÅŸÄ±laÅŸtÄ±rmasÄ±")
            
            st.markdown("""
            **GÃ¶zlem**: YukarÄ±daki grafik, her bir Ã¶znitelik seÃ§im yÃ¶nteminin farklÄ± metrikler aÃ§Ä±sÄ±ndan performansÄ±nÄ± gÃ¶stermektedir.
            Ã–znitelik sayÄ±sÄ±nÄ± azaltmamÄ±za raÄŸmen, tÃ¼m yÃ¶ntemler yÃ¼ksek performans sergiliyor ve tam Ã¶znitelik setine yakÄ±n sonuÃ§lar veriyor.
            """)
        
        # Bireysel metrik karÅŸÄ±laÅŸtÄ±rmalarÄ±
        col1, col2 = st.columns([1, 1])
        metrikler = ["accuracy", "auc", "f1", "precision", "recall"]
        
        for i, metrik in enumerate(metrikler):
            metrik_gorseli = [img for img in oznitelik_secimi_gorselleri if f"{metrik}_karsilastirma" in img]
            if metrik_gorseli:
                with col1 if i % 2 == 0 else col2:
                    st.image(metrik_gorseli[0], use_container_width=True,
                            caption=f"{metrik.title()} MetriÄŸi KarÅŸÄ±laÅŸtÄ±rmasÄ±")
        
        # PCA AÃ§Ä±klanan Varyans
        st.header("PCA: AÃ§Ä±klanan Varyans")
        pca_gorseli = [img for img in oznitelik_secimi_gorselleri if "pca_variance" in img]
        if pca_gorseli:
            st.image(pca_gorseli[0], use_container_width=True,
                    caption="PCA: AÃ§Ä±klanan Varyans OranÄ±")
            
            st.markdown("""
            **GÃ¶zlem**: Bu grafik, Temel BileÅŸenler Analizinde (PCA) her bir bileÅŸenin ne kadar varyans aÃ§Ä±kladÄ±ÄŸÄ±nÄ± gÃ¶stermektedir.
            Ä°lk birkaÃ§ bileÅŸen, veri setindeki varyansÄ±n bÃ¼yÃ¼k bir kÄ±smÄ±nÄ± aÃ§Ä±klamaktadÄ±r. 
            Ä°lk 10 bileÅŸen, toplam varyansÄ±n yaklaÅŸÄ±k %95'ini aÃ§Ä±klamaktadÄ±r. Bu, 30 Ã¶znitelikten 10'una dÃ¼ÅŸÃ¼ÅŸle bile
            veri setindeki bilgilerin Ã§oÄŸunu koruyabildiÄŸimizi gÃ¶sterir.
            """)
        
        # Ã–znitelik SkorlarÄ±
        st.header("Ã–znitelik Ã–nem SkorlarÄ±")
        
        # Sekmelerde yÃ¶ntemleri gÃ¶ster
        skor_gorsel_kategorileri = {
            "ANOVA F-deÄŸeri": "anova_f-degeri_skorlar.png",
            "Mutual Information": "mutual_information_skorlar.png",
            "Random Forest Ã–nem": "random_forest_onem_skorlar.png",
            "Gradient Boosting Ã–nem": "gradient_boosting_onem_skorlar.png"
        }
        
        tabs = st.tabs(list(skor_gorsel_kategorileri.keys()))
        
        for i, (tab_isim, gorsel_isim) in enumerate(skor_gorsel_kategorileri.items()):
            with tabs[i]:
                for gorsel in oznitelik_secimi_gorselleri:
                    if gorsel_isim in gorsel.lower():
                        st.image(gorsel, use_container_width=True, 
                                caption=f"{tab_isim} ile SeÃ§ilen Ã–zniteliklerin SkorlarÄ±")
                        break
        
        # En iyi yÃ¶ntem ve Ã¶znitelikler
        st.header("En Ä°yi Ã–znitelik Alt KÃ¼mesi")
        
        # En iyi Ã¶znitelikler dosyasÄ±nÄ± oku
        en_iyi_dosya = "goruntuler/oznitelik_secimi/en_iyi_oznitelikler.txt"
        if os.path.exists(en_iyi_dosya):
            with open(en_iyi_dosya, 'r') as f:
                en_iyi_icerik = f.read()
            
            st.code(en_iyi_icerik, language=None)
            
            st.markdown("""
            ### SonuÃ§ ve DeÄŸerlendirme
            
            YapÄ±lan Ã¶znitelik seÃ§imi analizi sonucunda, daha az sayÄ±da Ã¶znitelik kullanarak tÃ¼m Ã¶zniteliklerle 
            benzer veya daha iyi performans elde edebildiÄŸimizi gÃ¶rÃ¼yoruz. Bu, modellerimizin daha verimli ve yorumlanabilir 
            olmasÄ±nÄ± saÄŸlar.
            
            **Ã–nemli GÃ¶zlemler:**
            
            1. Ã–znitelik sayÄ±sÄ±nÄ± 30'dan 10'a dÃ¼ÅŸÃ¼rmemize raÄŸmen, model performansÄ±nda dÃ¼ÅŸÃ¼ÅŸ yaÅŸanmamÄ±ÅŸtÄ±r.
            2. "concave points" (iÃ§bÃ¼key noktalar) ile ilgili Ã¶znitelikler, birÃ§ok seÃ§im yÃ¶nteminde en Ã¶nemli Ã¶znitelikler arasÄ±nda yer almaktadÄ±r.
            3. "worst" (en kÃ¶tÃ¼) deÄŸerler kategorisindeki Ã¶zelliklerin Ã§oÄŸu, en Ã¶nemli Ã¶znitelikler arasÄ±nda seÃ§ilmiÅŸtir.
            4. PCA kullanarak boyut indirgeme yapÄ±ldÄ±ÄŸÄ±nda, ilk 10 bileÅŸen toplam varyansÄ±n %95'ini aÃ§Ä±klamaktadÄ±r.
            
            Bu sonuÃ§lar, meme kanseri tespitinde belirli morfolojik Ã¶zelliklerin daha belirleyici olduÄŸunu doÄŸrulamaktadÄ±r.
            Ä°leriki Ã§alÄ±ÅŸmalarda, yalnÄ±zca seÃ§ilen Ã¶nemli Ã¶znitelikleri kullanarak modelleri yeniden eÄŸitebilir ve 
            gerÃ§ek zamanlÄ± uygulamalar iÃ§in daha hÄ±zlÄ± bir sistem geliÅŸtirebiliriz.
            """)
        else:
            st.warning("En iyi Ã¶znitelikler dosyasÄ± bulunamadÄ±. LÃ¼tfen 'oznitelik_secimi.py' scriptini Ã§alÄ±ÅŸtÄ±rÄ±n.")

# Footer
st.markdown("---")
st.markdown("Â© 2023 Meme Kanseri Tespiti Projesi | Yapay Zeka ve Makine Ã–ÄŸrenmesi UygulamasÄ±") 